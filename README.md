<div align="center">
<h3>FaceBench: A Multi-View Multi-Level Facial Attribute VQA Dataset for Benchmarking Face Perception MLLMs</h3>
  
[![ArXiv](https://img.shields.io/badge/ArXiv-2503.21457-B31B1B.svg)](https://arxiv.org/pdf/2503.21457)

<img src="./assets/overview.png" width="100%" height="100%">

</div>

## News
* **[2024-03-27]** The paper is released on ArXiv.

## TODO
- [X] Release the inference code.
- [X] Release the training code.
- [X] Support image generation in a resolution of 512x512.
- [ ] Scale up the model size (based on LLaMA3) and increase the number of training data.

## Citation
If you find this work useful for your research, please consider citing our paper:
```
@inproceedings{wang2025facebench,
  title={FaceBench: A Multi-View Multi-Level Facial Attribute VQA Dataset for Benchmarking Face Perception MLLMs},
  author={Wang, Xiaoqin and Ma, Xusen and Hou, Xianxu and Ding, Meidan and Li, Yudong and Chen, Junliang and Chen, Wenting and Peng, Xiaoyang and Shen, Linlin},
  booktitle={Proceedings-2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2025},
  year={2025}
}
```

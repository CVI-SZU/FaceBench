<div align="center">
<h3>FaceBench: A Multi-View Multi-Level Facial Attribute VQA Dataset for Benchmarking Face Perception MLLMs [CVPR 2025]</h3>
Xiaoqin Wang, Xusen Ma, Xianxu Hou, Meidan Ding, Yudong Li, Junliang Chen, Wenting Chen, Xiaoyang Peng, Linlin Shen* 

  
[![ArXiv](https://img.shields.io/badge/ArXiv-2503.21457-B31B1B.svg)](https://arxiv.org/pdf/2503.21457)
[![Webpage](https://img.shields.io/badge/Webpage-FaceBench-<COLOR>.svg)](https://github.com/CVI-SZU/FaceBench/tree/main)
[![Dataset](https://img.shields.io/badge/HuggingFaceðŸ¤—-Dataset-blue)](https://github.com/CVI-SZU/FaceBench/tree/main)
[![Models](https://img.shields.io/badge/HuggingFaceðŸ¤—-Models-blue)](https://github.com/CVI-SZU/FaceBench/tree/main)

<img src="./assets/overview.png" width="100%" height="100%">

</div>

## News
* **[2024-03-27]** The paper is released on ArXiv.

## TODO
- [ ] Release the Face-LLaVA model and inference code.
- [ ] Release the evaluation code.
- [ ] Release the dataset.

## FaceBench Overview

## Experimental Results
- **Experimental results of various MLLMs and our Face-LLaVA across five facial attribute views.**
<p align="center">
    <img src="./assets/five-view-results.jpg" width="100%" height="50%">
</p>

- **Experimental results of various MLLMs and our Face-LLaVA across Level 1 facial attributes.**
<p align="center">
    <img src="./assets/level-1-results.jpg" width="100%" height="50%">
</p>

## Citation
If you find this work useful for your research, please consider citing our paper:
```
@inproceedings{wang2025facebench,
  title={FaceBench: A Multi-View Multi-Level Facial Attribute VQA Dataset for Benchmarking Face Perception MLLMs},
  author={Wang, Xiaoqin and Ma, Xusen and Hou, Xianxu and Ding, Meidan and Li, Yudong and Chen, Junliang and Chen, Wenting and Peng, Xiaoyang and Shen, Linlin},
  booktitle={Proceedings-2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2025},
  year={2025}
}
```

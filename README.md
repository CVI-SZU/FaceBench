<div align="center">
<h3>FaceBench: A Multi-View Multi-Level Facial Attribute VQA Dataset for Benchmarking Face Perception MLLMs [CVPR 2025]</h3>
[Xiaoqin Wang]
[Xusen Ma]
[Xianxu Hou]
[Meidan Ding]
[Yudong Li]
[Junliang Chen]
[Wenting Chen]
[Xiaoyang Peng]
[Linlin Shen]* 

  
[![ArXiv](https://img.shields.io/badge/ArXiv-2503.21457-B31B1B.svg)](https://arxiv.org/pdf/2503.21457) [![Webpage](https://img.shields.io/badge/Webpage-FaceBench-<COLOR>.svg)](https://github.com/CVI-SZU/FaceBench/tree/main)

<img src="./assets/overview.png" width="100%" height="100%">

</div>

## News
* **[2024-03-27]** The paper is released on ArXiv.

## TODO
- [ ] Release the Face-LLaVA model and inference code.
- [ ] Release the evaluation code.
- [ ] Release the dataset.

## Citation
If you find this work useful for your research, please consider citing our paper:
```
@inproceedings{wang2025facebench,
  title={FaceBench: A Multi-View Multi-Level Facial Attribute VQA Dataset for Benchmarking Face Perception MLLMs},
  author={Wang, Xiaoqin and Ma, Xusen and Hou, Xianxu and Ding, Meidan and Li, Yudong and Chen, Junliang and Chen, Wenting and Peng, Xiaoyang and Shen, Linlin},
  booktitle={Proceedings-2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2025},
  year={2025}
}
```
